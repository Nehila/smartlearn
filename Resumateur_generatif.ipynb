{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  Résumeur Génératif avec T5\n",
        "\n",
        "dans ce notebook nous entraîne un modèle génératif (T5-small) pour produire des résumés à partir des articles du dataset CNN/DailyMail. \n",
        "> ** Remarque** : L'entraînement complet sur tout le dataset est coûteux (GPU recommandé). Par défaut, nous utilisons un sous-ensemble pour valider la pipeline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Préparation de l'environnement\n",
        "\n",
        "\n",
        "```bash\n",
        "pip install -q transformers datasets accelerate sentencepiece rouge-score\n",
        "```\n",
        "\n",
        "\n",
        "```bash\n",
        "accelerate config\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.backends.mps.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " transformers version: 4.57.1\n",
            " Using device: mps\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import re\n",
        "import random\n",
        "import zipfile\n",
        "from typing import Dict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Vérifier la version de transformers\n",
        "import transformers\n",
        "print(f\" transformers version: {transformers.__version__}\")\n",
        "\n",
        "# Définir le device dès le début\n",
        "def get_device():\n",
        "    if torch.backends.mps.is_available():\n",
        "        return torch.device(\"mps\")\n",
        "    elif torch.cuda.is_available():\n",
        "        return torch.device(\"cuda\")\n",
        "    else:\n",
        "        return torch.device(\"cpu\")\n",
        "\n",
        "device = get_device()\n",
        "print(f\" Using device: {device}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration générale\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "BASE_DIR = os.getcwd()\n",
        "DATA_ZIP = os.path.join(BASE_DIR, \"dataset.zip\")\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"dataset\")\n",
        "CNN_DIR = os.path.join(DATA_DIR, \"cnn\", \"stories\")\n",
        "\n",
        "# Limites pour expérimentation rapide (ajustez selon vos ressources GPU)\n",
        "MAX_ARTICLES = 5000           # nombre d'articles chargés pour le nettoyage\n",
        "MAX_SAMPLES = 15000           # nombre d'articles utilisés pour l'entraînement T5\n",
        "MAX_TRAIN_SAMPLES = 12000\n",
        "MAX_VAL_SAMPLES = 2000\n",
        "MAX_TEST_SAMPLES = 1000\n",
        "\n",
        "MODEL_NAME = \"t5-small\"       # ou \"t5-base\"\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, \"models\", MODEL_NAME.replace(\"/\", \"_\"))\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Dataset déjà présent dans /Users/nouhailaenihe/Desktop/Projet_NLP/dataset\n"
          ]
        }
      ],
      "source": [
        "# Extraire la base de données si nécessaire\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    assert os.path.exists(DATA_ZIP), \"dataset.zip introuvable. Veuillez le placer dans le dossier du projet.\"\n",
        "    with zipfile.ZipFile(DATA_ZIP, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(DATA_DIR)\n",
        "    print(\" Dataset extrait dans\", DATA_DIR)\n",
        "else:\n",
        "    print(\" Dataset déjà présent dans\", DATA_DIR)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Télécharger les ressources NLTK nécessaires\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonctions utilitaires\n",
        "\n",
        "def parse_story_file(fp: str):\n",
        "    \"\"\"Parse un fichier .story et retourne (article, résumé).\"\"\"\n",
        "    with open(fp, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        lines = [l.strip() for l in f.readlines()]\n",
        "    \n",
        "    article_lines, highlights, in_highlight = [], [], False\n",
        "    for l in lines:\n",
        "        if l.lower() == \"@highlight\":\n",
        "            in_highlight = True\n",
        "            continue\n",
        "        if in_highlight:\n",
        "            if l:\n",
        "                highlights.append(l)\n",
        "        else:\n",
        "            if l:\n",
        "                article_lines.append(l)\n",
        "    \n",
        "    article = re.sub(r\"\\s+\", \" \", \" \".join(article_lines)).strip()\n",
        "    summary = re.sub(r\"\\s+\", \" \", \" \".join(highlights)).strip()\n",
        "    return article, summary\n",
        "\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    text = re.sub(r\"^\\(CNN\\)\\s*-*\\s*\", \"\", text)\n",
        "    text = re.sub(r\"\\(CNN\\)\\s*\", \"\", text)\n",
        "    text = re.sub(r\"--\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    text = text.replace(\"’\", \"'\").replace(\"“\", '\"').replace(\"”\", '\"')\n",
        "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
        "    return text.strip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 92579 fichiers .story disponibles\n",
            " Sous-échantillonnage à 5000 fichiers pour le nettoyage\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Lecture des fichiers: 100%|██████████| 5000/5000 [00:01<00:00, 3461.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Articles chargés : 4993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Chargement des articles\n",
        "files = glob.glob(os.path.join(CNN_DIR, \"*.story\"))\n",
        "print(f\" {len(files)} fichiers .story disponibles\")\n",
        "\n",
        "if MAX_ARTICLES is not None:\n",
        "    files = random.sample(files, min(MAX_ARTICLES, len(files)))\n",
        "    print(f\" Sous-échantillonnage à {len(files)} fichiers pour le nettoyage\")\n",
        "\n",
        "rows = []\n",
        "for fp in tqdm(files, desc=\"Lecture des fichiers\"):\n",
        "    article, summary = parse_story_file(fp)\n",
        "    if article and summary:\n",
        "        rows.append({\"article\": article, \"summary\": summary})\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "print(\"Articles chargés :\", len(df))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Nettoyage des textes...\n",
            " Doublons supprimés : 17\n",
            "       len_article  len_summary\n",
            "count       4976.0       4976.0\n",
            "mean        3916.3        255.5\n",
            "std         2018.9         56.4\n",
            "min          250.0         54.0\n",
            "25%         2290.8        215.0\n",
            "50%         3634.0        258.0\n",
            "75%         5239.0        300.0\n",
            "max        11415.0        447.0\n"
          ]
        }
      ],
      "source": [
        "# Nettoyage identique au pipeline extractif\n",
        "print(\" Nettoyage des textes...\")\n",
        "df[\"article\"] = df[\"article\"].apply(clean_text)\n",
        "df[\"summary\"] = df[\"summary\"].apply(clean_text)\n",
        "\n",
        "# Suppression des doublons\n",
        "before = len(df)\n",
        "df = df.drop_duplicates(subset=[\"article\", \"summary\"]).reset_index(drop=True)\n",
        "print(f\" Doublons supprimés : {before - len(df)}\")\n",
        "\n",
        "# Calcul longueurs pour diagnostic\n",
        "df[\"len_article\"] = df[\"article\"].str.len()\n",
        "df[\"len_summary\"] = df[\"summary\"].str.len()\n",
        "print(df[[\"len_article\", \"len_summary\"]].describe().round(1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Nombre d'exemples utilisés : 4976\n"
          ]
        }
      ],
      "source": [
        "# Option : réduire à MAX_SAMPLES pour entraînement plus rapide\n",
        "if MAX_SAMPLES and len(df) > MAX_SAMPLES:\n",
        "    df = df.sample(n=MAX_SAMPLES, random_state=SEED).reset_index(drop=True)\n",
        "    print(f\" Sous-échantillonnage à {len(df)} exemples pour l'entraînement T5\")\n",
        "else:\n",
        "    print(f\" Nombre d'exemples utilisés : {len(df)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 3980 | Val: 498 | Test: 498\n"
          ]
        }
      ],
      "source": [
        "# Split train / validation / test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, temp_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state=SEED\n",
        ")\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "if MAX_TRAIN_SAMPLES:\n",
        "    train_df = train_df.sample(n=min(MAX_TRAIN_SAMPLES, len(train_df)), random_state=SEED)\n",
        "if MAX_VAL_SAMPLES:\n",
        "    val_df = val_df.sample(n=min(MAX_VAL_SAMPLES, len(val_df)), random_state=SEED)\n",
        "if MAX_TEST_SAMPLES:\n",
        "    test_df = test_df.sample(n=min(MAX_TEST_SAMPLES, len(test_df)), random_state=SEED)\n",
        "\n",
        "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['article', 'summary'],\n",
              "        num_rows: 3980\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['article', 'summary'],\n",
              "        num_rows: 498\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['article', 'summary'],\n",
              "        num_rows: 498\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Conversion en HuggingFace Dataset\n",
        "hf_datasets = DatasetDict({\n",
        "    \"train\": Dataset.from_pandas(train_df[[\"article\", \"summary\"]]),\n",
        "    \"validation\": Dataset.from_pandas(val_df[[\"article\", \"summary\"]]),\n",
        "    \"test\": Dataset.from_pandas(test_df[[\"article\", \"summary\"]]),\n",
        "})\n",
        "\n",
        "# Supprimer la colonne d'index générée par pandas\n",
        "hf_datasets = hf_datasets.remove_columns([col for col in hf_datasets[\"train\"].column_names if col.startswith(\"__index\")])\n",
        "\n",
        "hf_datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Préfixe T5 pour summarization\n",
        "TASK_PREFIX = \"summarize: \"\n",
        "\n",
        "MAX_INPUT_LENGTH = 512\n",
        "MAX_TARGET_LENGTH = 128\n",
        "\n",
        "\n",
        "def preprocess_function(batch: Dict[str, list]) -> Dict[str, list]:\n",
        "    inputs = [TASK_PREFIX + article for article in batch[\"article\"]]\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=MAX_INPUT_LENGTH,\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    # Utiliser text_target au lieu de as_target_tokenizer (déprécié)\n",
        "    labels = tokenizer(\n",
        "        text_target=batch[\"summary\"],\n",
        "        max_length=MAX_TARGET_LENGTH,\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 3980/3980 [00:02<00:00, 1851.66 examples/s]\n",
            "Map: 100%|██████████| 498/498 [00:00<00:00, 2127.01 examples/s]\n",
            "Map: 100%|██████████| 498/498 [00:00<00:00, 2001.52 examples/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3980\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 498\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 498\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_datasets = hf_datasets.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"article\", \"summary\"]\n",
        ")\n",
        "\n",
        "tokenized_datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device déjà défini: mps\n"
          ]
        }
      ],
      "source": [
        "# Device déjà défini dans la cellule 3\n",
        "# Vérification que device est bien défini\n",
        "if 'device' not in globals():\n",
        "    device = get_device()\n",
        "    print(f\"Device défini: {device}\")\n",
        "else:\n",
        "    print(f\"Device déjà défini: {device}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 512)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-5): 5 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-5): 5 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "rouge_metric = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    # Calcul ROUGE moyenne sur le batch\n",
        "    rouge_scores = {\"rouge1\": [], \"rouge2\": [], \"rougeL\": []}\n",
        "    for pred, label in zip(decoded_preds, decoded_labels):\n",
        "        score = rouge_metric.score(target=label, prediction=pred)\n",
        "        for k, v in score.items():\n",
        "            rouge_scores[k].append(v.fmeasure)\n",
        "\n",
        "    result = {k: round(float(np.mean(v)) * 100, 4) for k, v in rouge_scores.items() if v}\n",
        "    return result\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ TrainingArguments créé avec arguments de base\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 4\n",
        "GRADIENT_ACCUMULATION_STEPS = 8\n",
        "EPOCHS = 3\n",
        "LEARNING_RATE = 5e-5\n",
        "WARMUP_STEPS = 500\n",
        "\n",
        "# Arguments de base compatibles avec toutes les versions\n",
        "base_args = {\n",
        "    \"output_dir\": OUTPUT_DIR,\n",
        "    \"per_device_train_batch_size\": BATCH_SIZE,\n",
        "    \"per_device_eval_batch_size\": BATCH_SIZE,\n",
        "    \"gradient_accumulation_steps\": GRADIENT_ACCUMULATION_STEPS,\n",
        "    \"num_train_epochs\": EPOCHS,\n",
        "    \"learning_rate\": LEARNING_RATE,\n",
        "    \"warmup_steps\": WARMUP_STEPS,\n",
        "    \"weight_decay\": 0.01,\n",
        "    \"logging_steps\": 100,\n",
        "    \"save_steps\": 500,\n",
        "    \"save_total_limit\": 2,\n",
        "    \"fp16\": torch.cuda.is_available(),\n",
        "    \"report_to\": [\"none\"]\n",
        "}\n",
        "\n",
        "# Ajouter les arguments optionnels selon la version\n",
        "try:\n",
        "    # Essayer les arguments modernes\n",
        "    training_args = TrainingArguments(**base_args)\n",
        "    print(\"✅ TrainingArguments créé avec arguments de base\")\n",
        "except TypeError as e:\n",
        "    # Si erreur, retirer les arguments problématiques\n",
        "    print(f\"⚠️ Erreur avec certains arguments: {e}\")\n",
        "    # Retirer les arguments qui pourraient causer problème\n",
        "    base_args.pop(\"report_to\", None)\n",
        "    base_args.pop(\"save_total_limit\", None)\n",
        "    training_args = TrainingArguments(**base_args)\n",
        "    print(\"✅ TrainingArguments créé avec arguments minimaux\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/2y/hcbdz6n92j9fz0y_zdrwxf2w0000gn/T/ipykernel_66398/1753765893.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Fine-tuning du modèle T5\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/nouhailaenihe/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [375/375 36:28, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.557400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.999200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.731000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "***** train metrics *****\n",
            "  epoch                    =        3.0\n",
            "  total_flos               =  1504145GF\n",
            "  train_loss               =     3.0109\n",
            "  train_runtime            = 0:36:34.97\n",
            "  train_samples_per_second =       5.44\n",
            "  train_steps_per_second   =      0.171\n"
          ]
        }
      ],
      "source": [
        "# Lance l'entraînement (décommentez pour exécuter)\n",
        "train_result = trainer.train()\n",
        "trainer.save_model(OUTPUT_DIR)\n",
        "tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "trainer.log_metrics(\"train\", train_result.metrics)\n",
        "trainer.save_metrics(\"train\", train_result.metrics)\n",
        "trainer.save_state()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Génération de résumés (inférence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_trained_model(model_path: str = OUTPUT_DIR):\n",
        "    \"\"\"Charge un modèle T5 fine-tuné depuis disk.\"\"\"\n",
        "    tok = AutoTokenizer.from_pretrained(model_path)\n",
        "    mdl = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "    return tok, mdl\n",
        "\n",
        "\n",
        "def generate_summary(article: str,\n",
        "                     model_path: str = OUTPUT_DIR,\n",
        "                     max_new_tokens: int = 128,\n",
        "                     num_beams: int = 4) -> str:\n",
        "    tok, mdl = load_trained_model(model_path)\n",
        "    mdl.eval()\n",
        "    inputs = tok(\n",
        "        TASK_PREFIX + article,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=MAX_INPUT_LENGTH\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        outputs = mdl.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            num_beams=num_beams,\n",
        "            early_stopping=True\n",
        "        )\n",
        "    return tok.decode(outputs[0], skip_special_tokens=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ARTICLE : New Haven, Connecticut A Connecticut doctor whose wife and two daughters were killed in a 2007 home invasion took the stand Tuesday to testify against one of the accused killers, recalling horrific details of being beaten and tied up by his alleged captors while fearing for the well-being of his family. William Petit, testifying on the trial's second day in New Haven Superior Court, calmly relayed ...\n",
            "\n",
            "RÉSUMÉ GÉNÉRÉ : William Petit testifies against one of the accused killers Steven Hayes, 47, and Joshua Komisarjevsky, 30, are charged with capital murder, kidnapping, sexual assault, burglary and arson They both could face the death penalty if convicted\n"
          ]
        }
      ],
      "source": [
        "# Exemple (décommentez après l'entraînement et la sauvegarde)\n",
        "sample_article = df[\"article\"].iloc[0]\n",
        "print(\"ARTICLE :\", sample_article[:400], \"...\")\n",
        "generated_summary = generate_summary(sample_article)\n",
        "print(\"\\nRÉSUMÉ GÉNÉRÉ :\", generated_summary)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chargement du modèle fine-tuné...\n",
            "Génération des résumés sur le set de test...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluation test: 100%|██████████| 498/498 [10:03<00:00,  1.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calcul des scores ROUGE...\n",
            "\n",
            " Résultats ROUGE sur le set de test:\n",
            "   ROUGE1: 33.59%\n",
            "   ROUGE2: 13.80%\n",
            "   ROUGEL: 23.75%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'rouge1': 33.59053456695846,\n",
              " 'rouge2': 13.804220334102277,\n",
              " 'rougeL': 23.750374955697488}"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Évaluation manuelle sur le set de test (après entraînement)\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "print(\"Chargement du modèle fine-tuné...\")\n",
        "tokenizer, model = load_trained_model(OUTPUT_DIR)\n",
        "\n",
        "print(\"Génération des résumés sur le set de test...\")\n",
        "references, predictions = [], []\n",
        "for sample in tqdm(hf_datasets[\"test\"], desc=\"Evaluation test\"):\n",
        "    generated = generate_summary(sample[\"article\"], model_path=OUTPUT_DIR)\n",
        "    references.append(sample[\"summary\"])\n",
        "    predictions.append(generated)\n",
        "\n",
        "print(\"Calcul des scores ROUGE...\")\n",
        "rouge_scores = {\"rouge1\": [], \"rouge2\": [], \"rougeL\": []}\n",
        "for pred, ref in zip(predictions, references):\n",
        "    score = rouge_metric.score(target=ref, prediction=pred)\n",
        "    for k, v in score.items():\n",
        "        rouge_scores[k].append(v.fmeasure)\n",
        "\n",
        "# Afficher les résultats\n",
        "results = {k: float(np.mean(v)) * 100 for k, v in rouge_scores.items()}\n",
        "print(\"\\n Résultats ROUGE sur le set de test:\")\n",
        "for metric, score in results.items():\n",
        "    print(f\"   {metric.upper()}: {score:.2f}%\")\n",
        "    \n",
        "results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
